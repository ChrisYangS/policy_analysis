{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Firstly, load the scrapped website data that was saved in json format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "At least one of TensorFlow 2.0 or PyTorch should be installed. To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ To install PyTorch, read the instructions at https://pytorch.org/.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Load a pre-trained sentiment analysis model\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m sentiment_analyzer \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msentiment-analysis\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/policy-analysis/lib/python3.12/site-packages/transformers/pipelines/__init__.py:940\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    939\u001b[0m     model_classes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[0;32m--> 940\u001b[0m     framework, model \u001b[38;5;241m=\u001b[39m \u001b[43minfer_framework_load_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframework\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframework\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    950\u001b[0m model_config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n\u001b[1;32m    951\u001b[0m hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39m_commit_hash\n",
      "File \u001b[0;32m~/anaconda3/envs/policy-analysis/lib/python3.12/site-packages/transformers/pipelines/base.py:240\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[0;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;124;03mSelect framework (TensorFlow or PyTorch) to use from the `model` passed. Returns a tuple (framework, model).\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03m    `Tuple`: A tuple framework, model.\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tf_available() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_available():\n\u001b[0;32m--> 240\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one of TensorFlow 2.0 or PyTorch should be installed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo install PyTorch, read the instructions at https://pytorch.org/.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    244\u001b[0m     )\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    246\u001b[0m     model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_from_pipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m task\n",
      "\u001b[0;31mRuntimeError\u001b[0m: At least one of TensorFlow 2.0 or PyTorch should be installed. To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ To install PyTorch, read the instructions at https://pytorch.org/."
     ]
    }
   ],
   "source": [
    "\n",
    "# import all libraries\n",
    "import json\n",
    "import ollama\n",
    "import tiktoken\n",
    "import sys\n",
    "import regex as re\n",
    "# import sanitize_filename from miscellaneous.py in ../utilities folder\n",
    "sys.path.insert(0, \"../utilities/\")\n",
    "from miscellaneous import sanitize_filename\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load a pre-trained sentiment analysis model\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guidelines\n",
      "Plans & Strategies\n",
      "Policies\n",
      "Procedures\n",
      "Regulations\n",
      "Statutes\n"
     ]
    }
   ],
   "source": [
    "dict = {}\n",
    "# read json file and save in policy_dict\n",
    "with open(\"../output/otago_policies_20250206102803.json\") as f:\n",
    "    dict = json.load(f)\n",
    "\n",
    "# then print all policy type in the dictionary key\n",
    "for key in dict.keys():\n",
    "    print(key)\n",
    "    \n",
    "# define selected llm model\n",
    "selected_llm = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create count_tokens function which takes in a text and encoding name as input and returns the number of tokens in the text.\n",
    "def count_tokens(text: str, encoding_name: str = \"cl100k_base\") -> int:\n",
    "    \"\"\"\n",
    "    Count the number of tokens in a given text using the specified encoding.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to count tokens for.\n",
    "        encoding_name (str): The name of the encoding to use. Default is \"cl100k_base\" (used by GPT-4 and similar models).\n",
    "\n",
    "    Returns:\n",
    "        int: The number of tokens in the text.\n",
    "    \"\"\"\n",
    "    # Get the encoding\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "\n",
    "    # Tokenize the text and count the tokens\n",
    "    tokens = encoding.encode(text)\n",
    "    return len(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get policy type list and policy\n",
    "def get_policy_type_details(policy_type: str) -> dict:\n",
    "    \"\"\"\n",
    "    Get the details of a policy type from the Otago University policies.\n",
    "\n",
    "    Args:\n",
    "        policy_type (str): The name of the policy type to get details for.\n",
    "\n",
    "    Returns:\n",
    "        dict: The details of the policy type.\n",
    "    \"\"\"\n",
    "    # Get the policy type details\n",
    "    policy_list = []\n",
    "\n",
    "    for item in dict[policy_type]:\n",
    "        policy_dict = {}\n",
    "        policy_dict[\"name\"] = item[\"name\"]\n",
    "        policy_dict[\"scope\"] = item[\"scope\"]\n",
    "        policy_dict[\"content\"] = item[\"content\"]\n",
    "        # append the policy_dict to policy_list\n",
    "        policy_list.append(policy_dict)\n",
    "    return policy_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Secondly, prepare all questions need to ask LLM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = \"Below is the policy data showing in JSON format, please list all policies that contain unnecessary content such as cross-references to other policies (there's a space for this in the policy documents, but not in the words of the policy itself)?\"\n",
    "\n",
    "q2 = \"Below is the policy data showing in JSON format, please list all policies that contain parts that are actually Procedures, not Policies (e.g. they contain instructions on how to do something, rather than rules or principles)?\"\n",
    "\n",
    "q3 = \"Below is the policy data showing in JSON format, please list all policies that contain inconsistencies or structural flaws. For example, if a policy is missing a section that is present in other policies, or if a policy has a section that is not relevant to the policy type?\"\n",
    "\n",
    "q4 = \"Below is the policy data showing in JSON format, please list all redundancy or incorrect structure of policy. It could be that there's a better way to structure the policy database, or that some policies are redundant or overlapping?\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then design functions to call Deepseek LLM model with api key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm_about_policy(question, data, model=\"deepseek-r1:14b\"):\n",
    "    # check number of questions\n",
    "    system_content = \"Below is a JSON format data contains one policy document record. Each record contains the following fields: 'name', 'scope', and 'content'. Please only answer question once you have read all the data.\"\n",
    "    \n",
    "    user_question_content = f\"{question}\\n: {str(data)}\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_content},\n",
    "        {\"role\": \"user\", \"content\": user_question_content},\n",
    "    ]\n",
    "    response = ollama.chat(\n",
    "        model=model, messages=messages\n",
    "    )\n",
    "    \n",
    "\n",
    "    # Extract and print the final response\n",
    "    if response:\n",
    "        return response\n",
    "    else: \n",
    "        # raise an exception\n",
    "        raise Exception(\"No response from the model\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_policy_list(policy_name: str, model_name):    \n",
    "    policy_list = get_policy_type_details(policy_name)\n",
    "    # show number of policy_list\n",
    "    print(f\"There are {len(policy_list)} items in the list.\")\n",
    "    # show number of policy_list tokens\n",
    "    print(f\"There are {count_tokens(str(policy_list))} tokens in the policy list.\")\n",
    "    total_policies = len(policy_list)\n",
    "    processed_document = 0\n",
    "    for policy in policy_list:\n",
    "        # ask question 1\n",
    "        response = call_llm_about_policy(q1, policy, model=model_name)\n",
    "        match = re.search(r\"</think>\\n*(.*)\", response.message.content)\n",
    "        policy_list[processed_document][\"q1_response\"] = match.group(1) if match else response.message.content\n",
    "        \n",
    "        # ask question 2\n",
    "        response = call_llm_about_policy(q2, policy, model=model_name)\n",
    "        match = re.search(r\"</think>\\n*(.*)\", response.message.content)\n",
    "        policy_list[processed_document][\"q2_response\"] = match.group(1) if match else response.message.content\n",
    "        \n",
    "        \n",
    "        # ask question 3\n",
    "        response = call_llm_about_policy(q3, policy, model=model_name)\n",
    "        match = re.search(r\"</think>\\n*(.*)\", response.message.content)\n",
    "        policy_list[processed_document][\"q3_response\"] = match.group(1) if match else response.message.content\n",
    "        \n",
    "        \n",
    "        # ask question 4\n",
    "        response = call_llm_about_policy(q4, policy, model=model_name)\n",
    "        match = re.search(r\"</think>\\n*(.*)\", response.message.content)\n",
    "        policy_list[processed_document][\"q4_response\"] = match.group(1) if match else response.message.content\n",
    "        \n",
    "        processed_document += 1\n",
    "        \n",
    "        print(f\"Processed {processed_document} of {total_policies} documents.\")\n",
    "    # printing out updated policy_list in JSON\n",
    "    with open(f\"./{sanitize_filename(f\"{policy_name}_{model_name}\")}.json\", \"w\") as f:\n",
    "        json.dump(policy_list, f, indent=4)\n",
    "    print(\n",
    "        f\"Updated policy list has been saved to {policy_name}_{model_name}_updated.json\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 54 items in the list.\n",
      "There are 75481 tokens in the policy list.\n",
      "Processed 1 of 54 documents.\n",
      "Processed 2 of 54 documents.\n",
      "Processed 3 of 54 documents.\n",
      "Processed 4 of 54 documents.\n",
      "Processed 5 of 54 documents.\n",
      "Processed 6 of 54 documents.\n",
      "Processed 7 of 54 documents.\n",
      "Processed 8 of 54 documents.\n",
      "Processed 9 of 54 documents.\n",
      "Processed 10 of 54 documents.\n",
      "Processed 11 of 54 documents.\n",
      "Processed 12 of 54 documents.\n",
      "Processed 13 of 54 documents.\n",
      "Processed 14 of 54 documents.\n",
      "Processed 15 of 54 documents.\n",
      "Processed 16 of 54 documents.\n",
      "Processed 17 of 54 documents.\n",
      "Processed 18 of 54 documents.\n",
      "Processed 19 of 54 documents.\n",
      "Processed 20 of 54 documents.\n",
      "Processed 21 of 54 documents.\n",
      "Processed 22 of 54 documents.\n",
      "Processed 23 of 54 documents.\n",
      "Processed 24 of 54 documents.\n",
      "Processed 25 of 54 documents.\n",
      "Processed 26 of 54 documents.\n",
      "Processed 27 of 54 documents.\n",
      "Processed 28 of 54 documents.\n",
      "Processed 29 of 54 documents.\n",
      "Processed 30 of 54 documents.\n",
      "Processed 31 of 54 documents.\n",
      "Processed 32 of 54 documents.\n",
      "Processed 33 of 54 documents.\n",
      "Processed 34 of 54 documents.\n",
      "Processed 35 of 54 documents.\n",
      "Processed 36 of 54 documents.\n",
      "Processed 37 of 54 documents.\n",
      "Processed 38 of 54 documents.\n",
      "Processed 39 of 54 documents.\n",
      "Processed 40 of 54 documents.\n",
      "Processed 41 of 54 documents.\n",
      "Processed 42 of 54 documents.\n",
      "Processed 43 of 54 documents.\n",
      "Processed 44 of 54 documents.\n",
      "Processed 45 of 54 documents.\n",
      "Processed 46 of 54 documents.\n",
      "Processed 47 of 54 documents.\n",
      "Processed 48 of 54 documents.\n",
      "Processed 49 of 54 documents.\n",
      "Processed 50 of 54 documents.\n",
      "Processed 51 of 54 documents.\n",
      "Processed 52 of 54 documents.\n",
      "Processed 53 of 54 documents.\n",
      "Processed 54 of 54 documents.\n",
      "Updated policy list has been saved to Guidelines_llama3.2_updated.json\n"
     ]
    }
   ],
   "source": [
    "update_policy_list(\"Guidelines\", model_name=selected_llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 items in the list.\n",
      "There are 87 tokens in the policy list.\n",
      "Processed 1 of 2 documents.\n",
      "Processed 2 of 2 documents.\n",
      "Updated policy list has been saved to Plans & Strategies_llama3.2_updated.json\n"
     ]
    }
   ],
   "source": [
    "update_policy_list(\"Plans & Strategies\", model_name=selected_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 119 items in the list.\n",
      "There are 148288 tokens in the policy list.\n",
      "Processed 1 of 119 documents.\n",
      "Processed 2 of 119 documents.\n",
      "Processed 3 of 119 documents.\n",
      "Processed 4 of 119 documents.\n",
      "Processed 5 of 119 documents.\n",
      "Processed 6 of 119 documents.\n",
      "Processed 7 of 119 documents.\n",
      "Processed 8 of 119 documents.\n",
      "Processed 9 of 119 documents.\n",
      "Processed 10 of 119 documents.\n",
      "Processed 11 of 119 documents.\n",
      "Processed 12 of 119 documents.\n",
      "Processed 13 of 119 documents.\n",
      "Processed 14 of 119 documents.\n",
      "Processed 15 of 119 documents.\n",
      "Processed 16 of 119 documents.\n",
      "Processed 17 of 119 documents.\n",
      "Processed 18 of 119 documents.\n",
      "Processed 19 of 119 documents.\n",
      "Processed 20 of 119 documents.\n",
      "Processed 21 of 119 documents.\n",
      "Processed 22 of 119 documents.\n",
      "Processed 23 of 119 documents.\n",
      "Processed 24 of 119 documents.\n",
      "Processed 25 of 119 documents.\n",
      "Processed 26 of 119 documents.\n",
      "Processed 27 of 119 documents.\n",
      "Processed 28 of 119 documents.\n",
      "Processed 29 of 119 documents.\n",
      "Processed 30 of 119 documents.\n",
      "Processed 31 of 119 documents.\n",
      "Processed 32 of 119 documents.\n",
      "Processed 33 of 119 documents.\n",
      "Processed 34 of 119 documents.\n",
      "Processed 35 of 119 documents.\n",
      "Processed 36 of 119 documents.\n",
      "Processed 37 of 119 documents.\n",
      "Processed 38 of 119 documents.\n",
      "Processed 39 of 119 documents.\n",
      "Processed 40 of 119 documents.\n",
      "Processed 41 of 119 documents.\n",
      "Processed 42 of 119 documents.\n",
      "Processed 43 of 119 documents.\n",
      "Processed 44 of 119 documents.\n",
      "Processed 45 of 119 documents.\n",
      "Processed 46 of 119 documents.\n",
      "Processed 47 of 119 documents.\n",
      "Processed 48 of 119 documents.\n",
      "Processed 49 of 119 documents.\n",
      "Processed 50 of 119 documents.\n",
      "Processed 51 of 119 documents.\n",
      "Processed 52 of 119 documents.\n",
      "Processed 53 of 119 documents.\n",
      "Processed 54 of 119 documents.\n",
      "Processed 55 of 119 documents.\n",
      "Processed 56 of 119 documents.\n",
      "Processed 57 of 119 documents.\n",
      "Processed 58 of 119 documents.\n",
      "Processed 59 of 119 documents.\n",
      "Processed 60 of 119 documents.\n",
      "Processed 61 of 119 documents.\n",
      "Processed 62 of 119 documents.\n",
      "Processed 63 of 119 documents.\n",
      "Processed 64 of 119 documents.\n",
      "Processed 65 of 119 documents.\n",
      "Processed 66 of 119 documents.\n",
      "Processed 67 of 119 documents.\n",
      "Processed 68 of 119 documents.\n",
      "Processed 69 of 119 documents.\n",
      "Processed 70 of 119 documents.\n",
      "Processed 71 of 119 documents.\n",
      "Processed 72 of 119 documents.\n",
      "Processed 73 of 119 documents.\n",
      "Processed 74 of 119 documents.\n",
      "Processed 75 of 119 documents.\n",
      "Processed 76 of 119 documents.\n",
      "Processed 77 of 119 documents.\n",
      "Processed 78 of 119 documents.\n",
      "Processed 79 of 119 documents.\n",
      "Processed 80 of 119 documents.\n",
      "Processed 81 of 119 documents.\n",
      "Processed 82 of 119 documents.\n",
      "Processed 83 of 119 documents.\n",
      "Processed 84 of 119 documents.\n",
      "Processed 85 of 119 documents.\n",
      "Processed 86 of 119 documents.\n",
      "Processed 87 of 119 documents.\n",
      "Processed 88 of 119 documents.\n",
      "Processed 89 of 119 documents.\n",
      "Processed 90 of 119 documents.\n",
      "Processed 91 of 119 documents.\n",
      "Processed 92 of 119 documents.\n",
      "Processed 93 of 119 documents.\n",
      "Processed 94 of 119 documents.\n",
      "Processed 95 of 119 documents.\n",
      "Processed 96 of 119 documents.\n",
      "Processed 97 of 119 documents.\n",
      "Processed 98 of 119 documents.\n",
      "Processed 99 of 119 documents.\n",
      "Processed 100 of 119 documents.\n",
      "Processed 101 of 119 documents.\n",
      "Processed 102 of 119 documents.\n",
      "Processed 103 of 119 documents.\n",
      "Processed 104 of 119 documents.\n",
      "Processed 105 of 119 documents.\n",
      "Processed 106 of 119 documents.\n",
      "Processed 107 of 119 documents.\n",
      "Processed 108 of 119 documents.\n",
      "Processed 109 of 119 documents.\n",
      "Processed 110 of 119 documents.\n",
      "Processed 111 of 119 documents.\n",
      "Processed 112 of 119 documents.\n",
      "Processed 113 of 119 documents.\n",
      "Processed 114 of 119 documents.\n",
      "Processed 115 of 119 documents.\n",
      "Processed 116 of 119 documents.\n",
      "Processed 117 of 119 documents.\n",
      "Processed 118 of 119 documents.\n",
      "Processed 119 of 119 documents.\n",
      "Updated policy list has been saved to Policies_llama3.2_updated.json\n"
     ]
    }
   ],
   "source": [
    "update_policy_list(\"Policies\", model_name=selected_llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 61 items in the list.\n",
      "There are 82778 tokens in the policy list.\n",
      "Processed 1 of 61 documents.\n",
      "Processed 2 of 61 documents.\n",
      "Processed 3 of 61 documents.\n",
      "Processed 4 of 61 documents.\n",
      "Processed 5 of 61 documents.\n",
      "Processed 6 of 61 documents.\n",
      "Processed 7 of 61 documents.\n",
      "Processed 8 of 61 documents.\n",
      "Processed 9 of 61 documents.\n",
      "Processed 10 of 61 documents.\n",
      "Processed 11 of 61 documents.\n",
      "Processed 12 of 61 documents.\n",
      "Processed 13 of 61 documents.\n",
      "Processed 14 of 61 documents.\n",
      "Processed 15 of 61 documents.\n",
      "Processed 16 of 61 documents.\n",
      "Processed 17 of 61 documents.\n",
      "Processed 18 of 61 documents.\n",
      "Processed 19 of 61 documents.\n",
      "Processed 20 of 61 documents.\n",
      "Processed 21 of 61 documents.\n",
      "Processed 22 of 61 documents.\n",
      "Processed 23 of 61 documents.\n",
      "Processed 24 of 61 documents.\n",
      "Processed 25 of 61 documents.\n",
      "Processed 26 of 61 documents.\n",
      "Processed 27 of 61 documents.\n",
      "Processed 28 of 61 documents.\n",
      "Processed 29 of 61 documents.\n",
      "Processed 30 of 61 documents.\n",
      "Processed 31 of 61 documents.\n",
      "Processed 32 of 61 documents.\n",
      "Processed 33 of 61 documents.\n",
      "Processed 34 of 61 documents.\n",
      "Processed 35 of 61 documents.\n",
      "Processed 36 of 61 documents.\n",
      "Processed 37 of 61 documents.\n",
      "Processed 38 of 61 documents.\n",
      "Processed 39 of 61 documents.\n",
      "Processed 40 of 61 documents.\n",
      "Processed 41 of 61 documents.\n",
      "Processed 42 of 61 documents.\n",
      "Processed 43 of 61 documents.\n",
      "Processed 44 of 61 documents.\n",
      "Processed 45 of 61 documents.\n",
      "Processed 46 of 61 documents.\n",
      "Processed 47 of 61 documents.\n",
      "Processed 48 of 61 documents.\n",
      "Processed 49 of 61 documents.\n",
      "Processed 50 of 61 documents.\n",
      "Processed 51 of 61 documents.\n",
      "Processed 52 of 61 documents.\n",
      "Processed 53 of 61 documents.\n",
      "Processed 54 of 61 documents.\n",
      "Processed 55 of 61 documents.\n",
      "Processed 56 of 61 documents.\n",
      "Processed 57 of 61 documents.\n",
      "Processed 58 of 61 documents.\n",
      "Processed 59 of 61 documents.\n",
      "Processed 60 of 61 documents.\n",
      "Processed 61 of 61 documents.\n",
      "Updated policy list has been saved to Procedures_llama3.2_updated.json\n"
     ]
    }
   ],
   "source": [
    "update_policy_list(\"Procedures\", model_name=selected_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9 items in the list.\n",
      "There are 13124 tokens in the policy list.\n",
      "Processed 1 of 9 documents.\n",
      "Processed 2 of 9 documents.\n",
      "Processed 3 of 9 documents.\n",
      "Processed 4 of 9 documents.\n",
      "Processed 5 of 9 documents.\n",
      "Processed 6 of 9 documents.\n",
      "Processed 7 of 9 documents.\n",
      "Processed 8 of 9 documents.\n",
      "Processed 9 of 9 documents.\n",
      "Updated policy list has been saved to Regulations_llama3.2_updated.json\n"
     ]
    }
   ],
   "source": [
    "update_policy_list(\"Regulations\", model_name=selected_llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After policies are analyzed by the LLM mode, we will perform a sentiment analysis on each policy's 4 questions' response and then mark down the positive and negative sentiment score for each policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 9 of 9 documents.\n"
     ]
    }
   ],
   "source": [
    "policy_name = \"Regulations\"\n",
    "with open(f\"./{sanitize_filename(f'{policy_name}_{selected_llm}')}.json\", \"r\") as f:\n",
    "    policy_list = json.load(f)\n",
    "\n",
    "total_policies = len(policy_list)\n",
    "processed_document = 0\n",
    "for policy in policy_list:\n",
    "    # determine the sentiment of the q1_response\n",
    "    q1_polarity = TextBlob(policy[\"q1_response\"]).sentiment.polarity\n",
    "    policy_list[processed_document][\"q1_positiveness\"] = (\n",
    "        \"positive\" if q1_polarity > 0 else \"negative\" if q1_polarity < 0 else \"neutral\"\n",
    "    )\n",
    "    q2_polarity = TextBlob(policy[\"q2_response\"]).sentiment.polarity\n",
    "    policy_list[processed_document][\"q2_positiveness\"] = (\n",
    "        \"positive\" if q2_polarity > 0 else \"negative\" if q2_polarity < 0 else \"neutral\"\n",
    "    )\n",
    "    q3_polarity = TextBlob(policy[\"q3_response\"]).sentiment.polarity\n",
    "    policy_list[processed_document][\"q3_positiveness\"] = (\n",
    "        \"positive\" if q3_polarity > 0 else \"negative\" if q3_polarity < 0 else \"neutral\"\n",
    "    )\n",
    "    q4_polarity = TextBlob(policy[\"q4_response\"]).sentiment.polarity\n",
    "    policy_list[processed_document][\"q4_positiveness\"] = (\n",
    "        \"positive\" if q4_polarity > 0 else \"negative\" if q4_polarity < 0 else \"neutral\"\n",
    "    )\n",
    "    processed_document += 1\n",
    "    \n",
    "print(f\"Processed {processed_document} of {total_policies} documents.\")\n",
    "\n",
    "# printing out updated policy_list in JSON\n",
    "# with open(f\"./{sanitize_filename(f'{policy_name}_{selected_llm}')}_updated.json\", \"w\") as f:\n",
    "#     json.dump(policy_list, f, indent=4)\n",
    "print(policy_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "policy-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
